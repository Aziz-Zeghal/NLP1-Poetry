{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d5b7a54",
   "metadata": {},
   "source": [
    "# Poem: Logistic Regression\n",
    "\n",
    "For this project, the text is the feature and the label is the date of the poem.\n",
    "\n",
    "We use logistic regression for a multi-class text classification task.\n",
    "\n",
    "With no preprocessing, the model has 304 targets. We will present the results of different models depending on the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6df80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85557f28",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6b5f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# Training\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "DATA = \"../data/\"\n",
    "BENCHMARK_TABLE = \"../../class_bench.parquet\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "if not os.path.exists(DATA):\n",
    "    raise FileNotFoundError(f\"Data directory {DATA} does not exist. Please create it and add the data files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e92565",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_df = pd.read_parquet(DATA + \"de_poems.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_df.head(3)[\"text\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec83287f",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from env import get_period\n",
    "\n",
    "poems = poems_df.copy()\n",
    "\n",
    "# Transform all date to centuries, else we have 304 classes\n",
    "poems[\"creation\"] = poems[\"creation\"].astype(int)\n",
    "\n",
    "# For model A\n",
    "poems[\"century\"] = poems[\"creation\"].apply(lambda x: str(x // 100 + 1))\n",
    "\n",
    "# For model B\n",
    "poems[\"movement\"] = poems[\"creation\"].apply(get_period)\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[\\d\\W_]+', ' ', text)\n",
    "    tokens = text.split()\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "poems[\"cleaned_text\"] = poems[\"text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems.head(3)[[\"text\", \"cleaned_text\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9d613",
   "metadata": {},
   "source": [
    "## Model creation and tuning\n",
    "\n",
    "When calling the `fit` method of the model, the y parameter will be different (either century or movement).\n",
    "\n",
    "We use SMOTE in order to create synthetic samples for the minority class (11th century).\n",
    "\n",
    "This reduces accuracy, but increases F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove german stop words\n",
    "german_stop_words = stopwords.words(\"german\")\n",
    "\n",
    "# Pipeline to fine-tune encoding and model\n",
    "# No need to fit_transform, pipeline will do it\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(stop_words=german_stop_words, ngram_range=(1, 2), max_df = 0.9, max_features=350000)),\n",
    "    # To keep the interesting features\n",
    "    (\"SMOTE\", SMOTE(random_state=RANDOM_STATE)),\n",
    "    (\"clf\", LogisticRegression(random_state = RANDOM_STATE, solver = \"sag\", penalty = \"l2\", max_iter = 100, verbose = 10, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "x = poems[\"cleaned_text\"]\n",
    "# y will be defined depending on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98bbb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For overall better config: penalty = \"L2\", solver = \"lbfgs\", max_iter = 100, max_features = 350000, ngram_range(1, 2)\n",
    "# For better accuracy on 19th, same thing with \"sag\"\n",
    "\n",
    "# https://stackoverflow.com/questions/44066264/how-to-choose-parameters-in-tfidfvectorizer-in-sklearn-during-unsupervised-clust\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = [\n",
    "    {\n",
    "    #    \"tfidf__max_df\": [0.9, 1.0],\n",
    "    #    \"tfidf__ngram_range\": [(1, 1), (1, 2), (1, 3)],\n",
    "    #    \"tfidf__max_features\": [200000, 250000, 300000, 350000],\n",
    "    #    \"clf__class_weight\": [None, \"balanced\"],\n",
    "    #    \"clf__class_weight\": [\"balanced\", None],\n",
    "    #    \"clf__solver\": [\"lbfgs\", \"sag\"],\n",
    "    #    \"clf__penalty\": [\"l1\", \"l2\"],\n",
    "    #    \"clf__max_iter\": [100, 350]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid, n_jobs = 2, cv = 3, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855fdff",
   "metadata": {},
   "source": [
    "# Model A: SMOTE, Per Century\n",
    "\n",
    "Each poem is mapped to a century.\n",
    "\n",
    "Our feature is `text`, and the label is `century`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf9100",
   "metadata": {},
   "source": [
    "## Step 1: Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = poems[\"century\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac228f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Currently have {len(poems)} poems with {len(y.unique())} dates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b2ef8",
   "metadata": {},
   "source": [
    "## Step 2: Data splitting and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e0f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476638ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "century_model = clf.best_estimator_\n",
    "century_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531973d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "century_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb095ad",
   "metadata": {},
   "source": [
    "#### Quick save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de62707",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(century_model, open(\"../trained/LR_Century_model_SMOTE_SAG.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be0532",
   "metadata": {},
   "source": [
    "## Step 3: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc9919",
   "metadata": {},
   "source": [
    "#### Quick load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6fc70dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "century_model = pickle.load(open(\"../trained/LR_Century_model_SMOTE_lbfgs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f38cb45",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e22a7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = century_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46caa9bb",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2cc04ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          11       0.34      0.58      0.43        55\n",
      "          13       0.73      0.44      0.55        18\n",
      "          14       0.75      0.79      0.77       189\n",
      "          16       0.95      0.84      0.89       210\n",
      "          17       0.91      0.90      0.90      4032\n",
      "          18       0.71      0.74      0.72      2880\n",
      "          19       0.87      0.78      0.82      6476\n",
      "          20       0.32      0.71      0.44       454\n",
      "\n",
      "    accuracy                           0.80     14314\n",
      "   macro avg       0.70      0.72      0.69     14314\n",
      "weighted avg       0.83      0.80      0.81     14314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred, zero_division=0))\n",
    "\n",
    "results = classification_report(y_test, y_pred, zero_division=0, output_dict=True)\n",
    "\n",
    "recall_avg = results[\"weighted avg\"][\"recall\"]\n",
    "f1_score_avg = results[\"weighted avg\"][\"f1-score\"]\n",
    "precision_avg = results[\"weighted avg\"][\"precision\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d5c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "heat = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=century_model.classes_)\n",
    "fig, ax = plt.subplots()  # optional: adjust figure size\n",
    "heat.plot(ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize it (row-wise percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Plot\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=century_model.classes_)\n",
    "disp.plot(values_format='.2f')  # values_format to control decimal places\n",
    "plt.title('Confusion Matrix (in %)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "177badfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Compare the results with the actual y values\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6386c48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Use predict_proba to get probabilities for each class\n",
    "y_pred_proba = century_model.predict_proba(x_test)\n",
    "\n",
    "# Compute ROC AUC score\n",
    "avg_roc = roc_auc_score(y_test, y_pred_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "print(f\"ROC AUC: {avg_roc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a778f1",
   "metadata": {},
   "source": [
    "### Saving for benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9331801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.read_parquet(BENCHMARK_TABLE)\n",
    "benchmark.loc[(\"TF-IDF\", \"Logistic Regression\"), [\"Avg Recall\", \"Avg F1-Score\", \"Avg Precision\", \"Accuracy\", \"Avg AUC\"]] = [\n",
    "    recall_avg, f1_score_avg, precision_avg, accuracy, avg_roc\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9127405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the benchmark table\n",
    "benchmark.to_parquet(BENCHMARK_TABLE, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2723b7",
   "metadata": {},
   "source": [
    "# Model B: SMOTE, Per Movement\n",
    "\n",
    "Each poem is mapped to a German literary movement.\n",
    "\n",
    "Our feature is `text`, and the label is `movement`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66404f9a",
   "metadata": {},
   "source": [
    "## Step 1: Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = poems[\"movement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Currently have {len(poems)} poems with {len(y.unique())} movements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f63f93",
   "metadata": {},
   "source": [
    "## Step 2: Data splitting and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2785f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a0926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136bb63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_model = clf.best_estimator_\n",
    "movement_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb03bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18f2a63",
   "metadata": {},
   "source": [
    "#### Quick save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74402f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(movement_model, open(\"../trained/LR_Movement_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f24eda",
   "metadata": {},
   "source": [
    "## Step 3: Evaluation and finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a45e41",
   "metadata": {},
   "source": [
    "#### Quick load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load just in case\n",
    "model = pickle.load(open(\"../trained/LR_Movement_model.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c355abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = movement_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adadcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "heat = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=movement_model.classes_)\n",
    "fig, ax = plt.subplots()  # optional: adjust figure size\n",
    "heat.plot(ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f9585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize it (row-wise percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Plot\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=movement_model.classes_)\n",
    "disp.plot(values_format='.2f')  # values_format to control decimal places\n",
    "plt.title('Confusion Matrix (in %)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results with the actual y values\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
