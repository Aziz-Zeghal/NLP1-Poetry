{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poetry Generation with Word2Vec & N-grams\n",
    "\n",
    "This notebook explores the fusion of Word2Vec embeddings and N-gram analysis to generate English poetry. By combining semantic understanding from Word2Vec with structural patterns from N-grams, we create novel poetic compositions that maintain both meaning and form. The implementation processes English poetry datasets to learn poetic patterns and generate new verses that capture the essence of traditional poetry while introducing innovative word combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/danedebastos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import random\n",
    "import nltk\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import rouge\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Configuration des param√®tres\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA = \"./data/en_poems.parquet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Loading data into a DataFrame (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Song for an Unwritten Play.</td>\n",
       "      <td>The moon's a drowsy fool to-night,\n",
       "Wrapped in ...</td>\n",
       "      <td>Shanks, Edward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Cup.</td>\n",
       "      <td>As a hot traveller\n",
       "Going through stones and sa...</td>\n",
       "      <td>Shanks, Edward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Rhymeless Song.</td>\n",
       "      <td>Rhyme with its jingle still betrays\n",
       "The song t...</td>\n",
       "      <td>Shanks, Edward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meadow and Orchard.</td>\n",
       "      <td>My heart is like a meadow,\n",
       "Where clouds go ove...</td>\n",
       "      <td>Shanks, Edward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who thinks that he possesses.</td>\n",
       "      <td>Who thinks that he possesses\n",
       "His mistress with...</td>\n",
       "      <td>Shanks, Edward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "0    Song for an Unwritten Play.   \n",
       "1                       The Cup.   \n",
       "2              A Rhymeless Song.   \n",
       "3            Meadow and Orchard.   \n",
       "4  Who thinks that he possesses.   \n",
       "\n",
       "                                                text          author  \n",
       "0  The moon's a drowsy fool to-night,\n",
       "Wrapped in ...  Shanks, Edward  \n",
       "1  As a hot traveller\n",
       "Going through stones and sa...  Shanks, Edward  \n",
       "2  Rhyme with its jingle still betrays\n",
       "The song t...  Shanks, Edward  \n",
       "3  My heart is like a meadow,\n",
       "Where clouds go ove...  Shanks, Edward  \n",
       "4  Who thinks that he possesses\n",
       "His mistress with...  Shanks, Edward  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA)\n",
    "df = df.astype({\"title\": \"string\", \"text\": \"string\", \"author\": \"string\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ' '.join(df['text'].astype(str).tolist())\n",
    "    \n",
    "\n",
    "text = re.sub(r'[^\\w\\s]', ' ', all_text.lower())\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "current_sentence = []\n",
    "\n",
    "for token in tokens:\n",
    "    current_sentence.append(token)\n",
    "    if token in ['.', '!', '?', ';'] or len(current_sentence) > 15:\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "\n",
    "if current_sentence:\n",
    "    sentences.append(current_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(116809481, 150443030)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w2v_model = Word2Vec(sentences=sentences, \n",
    "                    vector_size=100,\n",
    "                    window=5,\n",
    "                    min_count=2,\n",
    "                    workers=4)\n",
    "\n",
    "w2v_model.train(sentences, total_examples=len(sentences), epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-GRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_models = {}\n",
    "    \n",
    "for n in range(2, 5):\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    \n",
    "    ngram_model = defaultdict(list)\n",
    "    \n",
    "    for gram in n_grams:\n",
    "        key = tuple(gram[:-1])\n",
    "        value = gram[-1]\n",
    "        ngram_model[key].append(value)\n",
    "    \n",
    "    for key in ngram_model:\n",
    "        ngram_model[key] = Counter(ngram_model[key])\n",
    "    \n",
    "    ngram_models[n] = ngram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poem Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(w2v_model, ngram_models, seed_words, num_lines=5, line_length=7, creativity=0):\n",
    "    \"\"\"\n",
    "    Generate a poem using Word2Vec and n-gram models\n",
    "    \n",
    "    Parameters:\n",
    "    - w2v_model: Trained Word2Vec model\n",
    "    - ngram_models: Dictionary of n-gram models\n",
    "    - seed_words: List of words to start with\n",
    "    - num_lines: Number of lines in the poem\n",
    "    - line_length: Approximate number of words per line\n",
    "    - creativity: 0.0 to 1.0, higher means more Word2Vec influence vs. n-gram\n",
    "    \"\"\"\n",
    "    \n",
    "    poem = []\n",
    "    current_line = []\n",
    "    vocabulary = list(w2v_model.wv.index_to_key)\n",
    "    \n",
    "    # Start with a seed word\n",
    "    current_word = seed_words\n",
    "    current_line.append(current_word)\n",
    "    \n",
    "    for _ in range(num_lines * line_length):\n",
    "        next_word = None\n",
    "        \n",
    "        # Decide whether to use n-gram or Word2Vec based on creativity parameter\n",
    "        if random.random() > creativity:\n",
    "            for n in range(min(4, len(current_line) + 1), 1, -1):\n",
    "                if len(current_line) >= n - 1:\n",
    "                    key = tuple(current_line[-(n-1):])\n",
    "                    if key in ngram_models[n]:\n",
    "                        candidates = ngram_models[n][key]\n",
    "                        next_word = random.choices(\n",
    "                            list(candidates.keys()),\n",
    "                            weights=list(candidates.values()),\n",
    "                            k=1\n",
    "                        )[0]\n",
    "                        break\n",
    "        \n",
    "        if next_word is None:\n",
    "            try:\n",
    "                similar_words = w2v_model.wv.most_similar(current_word, topn=10)\n",
    "                next_word = random.choice(similar_words)[0]\n",
    "            except:\n",
    "                next_word = random.choice(vocabulary)\n",
    "        \n",
    "        current_line.append(next_word)\n",
    "        \n",
    "        if len(current_line) >= line_length:\n",
    "            poem.append(' '.join(current_line))\n",
    "            current_line = []\n",
    "\n",
    "            if poem:\n",
    "                last_line_words = poem[-1].split()\n",
    "                seed_word = random.choice(last_line_words)\n",
    "                try:\n",
    "                    candidates = w2v_model.wv.most_similar(seed_word, topn=5)\n",
    "                    current_word = random.choice(candidates)[0]\n",
    "                except:\n",
    "                    current_word = random.choice(vocabulary)\n",
    "                current_line.append(current_word)\n",
    "    \n",
    "    return '\\n'.join(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love passion of his faith life\n",
      "hope by dint of hopes hopes\n",
      "hope and faith restore love pain\n",
      "that was because o which yet\n",
      "which miltonic mean itself miltonic whatsoever\n",
      "self interest spirit itself itself looked\n",
      "presence image of soul and flesh\n"
     ]
    }
   ],
   "source": [
    "poem = generate_poem(\n",
    "        w2v_model=w2v_model,\n",
    "        ngram_models=ngram_models,\n",
    "        seed_words=\"love\",\n",
    "        num_lines=6,\n",
    "        line_length=6,\n",
    "        creativity=0  # Balance between structure (n-grams) and creativity (Word2Vec)\n",
    "    )\n",
    "\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:01<00:00, 14.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "prompts = [\n",
    "    \"It never ends\",\n",
    "    \"The moonlight dances\",\n",
    "    \"Darkness falls quickly\",\n",
    "    \"Beneath the willow tree\",\n",
    "    \"Whispers in the wind\",\n",
    "    \"I dreamed of fire\",\n",
    "    \"The silence grew louder\",\n",
    "    \"Stars fell like rain\",\n",
    "    \"Time forgets no one\",\n",
    "    \"A rose in winter\",\n",
    "    \"Shadows crawl at dawn\",\n",
    "    \"My heart is a lantern\",\n",
    "    \"Echoes of your name\",\n",
    "    \"Frozen in memory\",\n",
    "    \"We walked on glass\",\n",
    "    \"The sky swallowed the sun\",\n",
    "    \"Love fades to smoke\",\n",
    "    \"Buried beneath the snow\",\n",
    "    \"A storm without sound\",\n",
    "    \"Hope wears thin threads\"\n",
    "]\n",
    "\n",
    "all_poems = df[\"text\"].tolist()\n",
    "\n",
    "poem_embeddings = model.encode(all_poems, convert_to_tensor=True)\n",
    "\n",
    "best_refs = []\n",
    "\n",
    "for prompt in tqdm(prompts):\n",
    "    prompt_embedding = model.encode(prompt, convert_to_tensor=True)\n",
    "    similarities = util.cos_sim(prompt_embedding, poem_embeddings)[0]\n",
    "    best_index = similarities.argmax().item()\n",
    "    best_poem = all_poems[best_index]\n",
    "    best_refs.append(best_poem)\n",
    "    #print(f\"\\nPrompt: {prompt}\\nBest Reference Poem:\\n{best_poem}\\n{'-'*80}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po√®me g√©n√©r√©:\n",
      "It never fashon fer the fowl his bewailing\n",
      "illnesses lwow arsniew robustious branwen and guinivere\n",
      "strokonoff meknop serge lwow ars√©niew of lwow\n",
      "tschitsshakoff and roguenoff blanchefleur blanchefleur snote more\n",
      "exaltavit humiles and slowly lifting up lira\n",
      "until fat because till people know what\n",
      "guess understand insane yes reckon d reckon\n",
      "think believe when it tells believe to\n",
      "while from all depths that sink until\n",
      "melt sink steal melts among the hills\n",
      "breaks strikes the cymbal rises pours out\n",
      "\n",
      "Po√®me de r√©f√©rence:\n",
      "Friends... old friends...\n",
      "One sees how it ends.\n",
      "A woman looks\n",
      "Or a man tells lies,\n",
      "And the pleasant brooks\n",
      "And the quiet skies,\n",
      "Ruined with brawling\n",
      "And caterwauling,\n",
      "Enchant no more\n",
      "As they did before.\n",
      "And so it ends\n",
      "With friends.\n",
      "Friends... old friends...\n",
      "And what if it ends?\n",
      "Shall we dare to shirk\n",
      "What we live to learn?\n",
      "It has done its work,\n",
      "It has served its turn;\n",
      "And, forgive and forget\n",
      "Or hanker and fret,\n",
      "We can be no more\n",
      "As we were before.\n",
      "When it ends, it ends\n",
      "With friends.\n",
      "Friends... old friends...\n",
      "So it breaks, so it ends.\n",
      "There let it rest!\n",
      "It has fought and won,\n",
      "And is still the best\n",
      "That either has done.\n",
      "Each as he stands\n",
      "The work of its hands,\n",
      "Which shall be more\n",
      "As he was before?...\n",
      "What is it ends\n",
      "With friends?\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge1: 0.1435\n",
      "rouge2: 0.009\n",
      "rougeL: 0.0987\n",
      "rougeLsum: 0.1435\n",
      "\n",
      "BERTScore:\n",
      "Precision: 0.7418\n",
      "Recall: 0.7735\n",
      "F1: 0.7573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# G√©n√©rer le po√®me avec le prompt\n",
    "generated_poem = generate_poem(\n",
    "    w2v_model, \n",
    "    ngram_models, \n",
    "    \"It never\",\n",
    "    num_lines=10,\n",
    "    line_length=7,\n",
    "    creativity=0\n",
    ")\n",
    "\n",
    "# Charger les m√©triques d'√©valuation\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "# Calculer les scores ROUGE et BERTScore\n",
    "rouge_score = rouge.compute(predictions=[generated_poem], references=[best_refs[0]])\n",
    "bert_score = bertscore.compute(predictions=[generated_poem], references=[best_refs[0]], lang=\"en\")\n",
    "\n",
    "# Afficher les r√©sultats\n",
    "print(\"Po√®me g√©n√©r√©:\")\n",
    "print(generated_poem)\n",
    "print(\"\\nPo√®me de r√©f√©rence:\")\n",
    "print(best_refs[0])\n",
    "\n",
    "print(\"\\nROUGE Scores:\")\n",
    "for key, val in rouge_score.items():\n",
    "    print(f\"{key}: {round(val, 4)}\")\n",
    "\n",
    "print(\"\\nBERTScore:\")\n",
    "print(\"Precision:\", round(bert_score[\"precision\"][0], 4))\n",
    "print(\"Recall:\", round(bert_score[\"recall\"][0], 4))\n",
    "print(\"F1:\", round(bert_score[\"f1\"][0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       string[python]\n",
       "text        string[python]\n",
       "author      string[python]\n",
       "creation            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_parquet(\"../data/en_poems.parquet\")\n",
    "df2 = pd.read_parquet(\"../data/de_translated_en.parquet\")\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df = df.astype({\"title\": \"string\", \"text\": \"string\", \"author\": \"string\"})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = ' '.join(df['text'].astype(str).tolist())\n",
    "    \n",
    "# Basic cleaning\n",
    "text = re.sub(r'[^\\w\\s]', ' ', all_text.lower())\n",
    "text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# Tokenize text\n",
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "current_sentence = []\n",
    "\n",
    "for token in tokens:\n",
    "    current_sentence.append(token)\n",
    "    if token in ['.', '!', '?', ';'] or len(current_sentence) > 15:\n",
    "        sentences.append(current_sentence)\n",
    "        current_sentence = []\n",
    "\n",
    "if current_sentence:  # Add any remaining tokens\n",
    "    sentences.append(current_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161042643, 209310990)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w2v_model = Word2Vec(sentences=sentences, \n",
    "                    vector_size=100,\n",
    "                    window=5,\n",
    "                    min_count=2,\n",
    "                    workers=4)\n",
    "\n",
    "w2v_model.train(sentences, total_examples=len(sentences), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_models = {}\n",
    "    \n",
    "for n in range(2, 5):\n",
    "    # Generate n-grams\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    \n",
    "    # Build a model that predicts the next word based on previous n-1 words\n",
    "    ngram_model = defaultdict(list)\n",
    "    \n",
    "    for gram in n_grams:\n",
    "        key = tuple(gram[:-1])\n",
    "        value = gram[-1]\n",
    "        ngram_model[key].append(value)\n",
    "    \n",
    "    # Convert lists to frequency distributions\n",
    "    for key in ngram_model:\n",
    "        ngram_model[key] = Counter(ngram_model[key])\n",
    "    \n",
    "    ngram_models[n] = ngram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Po√®me g√©n√©r√©:\n",
      "It never hienge pendragon olivers olivers follow melodist\n",
      "caoutchouc or colada colada durindale mundum shellow\n",
      "seggt de herr eglamour eglamour sir launcelot\n",
      "nar em dat l√§pel tweit morgadour sir\n",
      "denys fogelsang olaf the patrik read loudly\n",
      "lewis eustace fogelsang and ambrose higham and\n",
      "hugh tallant pass in valentyne ambrose gazed\n",
      "hugh de valentyne doth tomas lamorak lewis\n",
      "may beautiful could seem must i shall\n",
      "wonderful wonderfully swam back our big goal\n",
      "richly costly the delicately gifted hermes swings\n",
      "\n",
      "Po√®me de r√©f√©rence:\n",
      "Friends... old friends...\n",
      "One sees how it ends.\n",
      "A woman looks\n",
      "Or a man tells lies,\n",
      "And the pleasant brooks\n",
      "And the quiet skies,\n",
      "Ruined with brawling\n",
      "And caterwauling,\n",
      "Enchant no more\n",
      "As they did before.\n",
      "And so it ends\n",
      "With friends.\n",
      "Friends... old friends...\n",
      "And what if it ends?\n",
      "Shall we dare to shirk\n",
      "What we live to learn?\n",
      "It has done its work,\n",
      "It has served its turn;\n",
      "And, forgive and forget\n",
      "Or hanker and fret,\n",
      "We can be no more\n",
      "As we were before.\n",
      "When it ends, it ends\n",
      "With friends.\n",
      "Friends... old friends...\n",
      "So it breaks, so it ends.\n",
      "There let it rest!\n",
      "It has fought and won,\n",
      "And is still the best\n",
      "That either has done.\n",
      "Each as he stands\n",
      "The work of its hands,\n",
      "Which shall be more\n",
      "As he was before?...\n",
      "What is it ends\n",
      "With friends?\n",
      "\n",
      "ROUGE Scores:\n",
      "rouge1: 0.0628\n",
      "rouge2: 0.0\n",
      "rougeL: 0.0628\n",
      "rougeLsum: 0.0628\n",
      "\n",
      "BERTScore:\n",
      "Precision: 0.7174\n",
      "Recall: 0.7594\n",
      "F1: 0.7378\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# G√©n√©rer le po√®me avec le prompt\n",
    "generated_poem = generate_poem(\n",
    "    w2v_model, \n",
    "    ngram_models, \n",
    "    \"It never\",\n",
    "    num_lines=10,\n",
    "    line_length=7,\n",
    "    creativity=0.4\n",
    ")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
