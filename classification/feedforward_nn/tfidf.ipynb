{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2ac419",
   "metadata": {},
   "source": [
    "# Poem: Feedforward Neural Network\n",
    "\n",
    "We use a feedforward neural network to classify the poems. The model is a simple logistic regression model with a single hidden layer. The input is the poem text, and the output is the date of the poem.\n",
    "\n",
    "This model requires less tweaking than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced6e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have stopwords\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd19c0",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Training\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.api.models import Model, Sequential\n",
    "from keras.api.layers import Dense, Input, Dropout\n",
    "from keras.api.optimizers import Adam\n",
    "from keras.api.losses import SparseCategoricalCrossentropy\n",
    "from keras.api.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "# Plot metrics\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Deactivate XLA compilation\n",
    "tf.config.optimizer.set_jit(False)\n",
    "# TensorFlow, check if GPU is available\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "DATA = \"../data/\"\n",
    "BENCHMARK_TABLE = \"../../class_bench.parquet\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "if not os.path.exists(DATA):\n",
    "    raise FileNotFoundError(f\"Data directory {DATA} does not exist. Please create it and add the data files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_df = pd.read_parquet(DATA + \"de_poems.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852c07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_df.head(3)[\"text\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43676d61",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1bc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from env import get_period\n",
    "\n",
    "poems = poems_df.copy()\n",
    "\n",
    "# Transform all date to centuries, else we have 304 classes\n",
    "poems[\"creation\"] = poems[\"creation\"].astype(int)\n",
    "\n",
    "# For model A\n",
    "poems[\"century\"] = poems[\"creation\"].apply(lambda x: str(x // 100 + 1))\n",
    "\n",
    "# For model B\n",
    "poems[\"movement\"] = poems[\"creation\"].apply(get_period)\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[\\d\\W_]+', ' ', text)\n",
    "    tokens = text.split()\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "poems[\"cleaned_text\"] = poems[\"text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems.head(3)[[\"text\", \"cleaned_text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90606217",
   "metadata": {},
   "source": [
    "## Model creation and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de34335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove german stop words\n",
    "german_stop_words = stopwords.words(\"german\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=german_stop_words)\n",
    "x = vectorizer.fit_transform(poems[\"cleaned_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b569e0e6",
   "metadata": {},
   "source": [
    "# Model A: Per Century\n",
    "\n",
    "Each poem is mapped to a century.\n",
    "\n",
    "Our feature is `text`, and the label is `century`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230f86d",
   "metadata": {},
   "source": [
    "## Step 1: Feature selection & class weight distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3398e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "labeler = LabelEncoder()\n",
    "y = labeler.fit_transform(poems[\"century\"])\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_values = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = dict(zip(np.unique(y), class_weight_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998ffc9",
   "metadata": {},
   "source": [
    "## Step 2: Data splitting and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd072e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab1305",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_dim = x_train.shape[1]\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Model\n",
    "poem_input = Input(shape=(poem_dim,), name=\"input\")\n",
    "\n",
    "# Hidden layers\n",
    "hidden_layers = Sequential(\n",
    "    [\n",
    "        Dense(128, activation=\"relu\", name=\"dense_1\"),\n",
    "        Dropout(0.2, name=\"dropout_1\"),\n",
    "        Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "        Dense(num_classes, activation=\"softmax\", name=\"output\"),\n",
    "    ], name=\"hidden_layers\"\n",
    ")\n",
    "poem_nn = hidden_layers(poem_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ad896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=poem_input, outputs=poem_nn, name=\"poem_model\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=SparseCategoricalCrossentropy(),\n",
    "    metrics=[SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc82f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=6,\n",
    "    batch_size=1024,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3, restore_best_weights=True)],\n",
    "    class_weight=class_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d01d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=hist.history[\"val_loss\"],\n",
    "    mode=\"lines\",\n",
    "    name=\"Validation Loss\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=hist.history[\"loss\"],\n",
    "    mode=\"lines\",\n",
    "    name=\"Train Loss\"\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Validation loss per epoch\",\n",
    "    xaxis_title=\"Epoch\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    legend_title=\"Dataset\",\n",
    "    xaxis=dict(tickmode=\"linear\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4485e",
   "metadata": {},
   "source": [
    "#### Quick save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90775d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../trained/ffnn_weighted.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8213540c",
   "metadata": {},
   "source": [
    "## Step 3: Evaluation\n",
    "\n",
    "y_pred is a matrix of probabilities for each class.\n",
    "\n",
    "We convert it to the label (encoded) with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b31b6",
   "metadata": {},
   "source": [
    "#### Quick load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f266ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load just in case\n",
    "model = keras.models.load_model(\"../trained/ffnn_weighted.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb109c",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa2659",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_classes, target_names=labeler.classes_, zero_division=0)[\"f1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df42edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "heat = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labeler.classes_)\n",
    "fig, ax = plt.subplots()  # optional: adjust figure size\n",
    "heat.plot(ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize it (row-wise percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Plot\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=labeler.classes_)\n",
    "disp.plot(values_format='.2f')  # values_format to control decimal places\n",
    "plt.title('Confusion Matrix (in %)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00180dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the results with the actual y values\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb032f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
