{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erwinrodrigues/school/nlp/project/NLP1-Poetry/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "\n",
    "DATA = \"../../data/en_poems.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model / Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoemGeneratorMLP(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_size, vocab_size, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, vocab_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "    \n",
    "class PoemDataset(Dataset):\n",
    "    def __init__(self, sequences, word2vec_model, vocab):\n",
    "        self.sequences = sequences\n",
    "        self.word2vec_model = word2vec_model\n",
    "        self.vocab = vocab\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get current word and next word\n",
    "        current_word = self.sequences[idx][0]\n",
    "        next_word = self.sequences[idx][1]\n",
    "\n",
    "        # Get word vector for current word\n",
    "        if current_word in self.word2vec_model.wv:\n",
    "            word_vector = self.word2vec_model.wv[current_word]\n",
    "        else:\n",
    "            word_vector = np.zeros(self.word2vec_model.vector_size)\n",
    "\n",
    "        # Get index of next word\n",
    "        next_word_idx = self.word_to_idx.get(next_word, 0)\n",
    "\n",
    "        return torch.tensor(word_vector, dtype=torch.float32), torch.tensor(\n",
    "            next_word_idx, dtype=torch.long\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_sequences(poems, window_size=2):\n",
    "    sequences = []\n",
    "    for poem in poems:\n",
    "        tokens = word_tokenize(re.sub(r\"[^\\w\\s]\", \" \", poem.lower()).strip())\n",
    "        for i in range(len(tokens) - 1):\n",
    "            sequences.append((tokens[i], tokens[i + 1]))\n",
    "    return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_poem_generator(\n",
    "    model, train_loader, test_loader, loss_fn, optimizer, num_epochs=50\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    best_test_loss = float(\"inf\")\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Train]\")\n",
    "\n",
    "        for batch_X, batch_y in train_pbar:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            train_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        test_pbar = tqdm(test_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Test]\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_pbar:\n",
    "                batch_X = batch_X.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "\n",
    "                outputs = model(batch_X)\n",
    "                loss = loss_fn(outputs, batch_y)\n",
    "                total_test_loss += loss.item()\n",
    "                test_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n",
    "        print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Average Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "        if avg_test_loss < best_test_loss:\n",
    "            best_test_loss = avg_test_loss\n",
    "            torch.save(model.state_dict(), \"best_poem_model.pt\")\n",
    "\n",
    "    return train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA)\n",
    "\n",
    "df[\"tokens\"] = df[\"text\"].apply(\n",
    "    lambda x: word_tokenize(re.sub(r\"[^\\w\\s]\", \" \", x.lower()).strip())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116510229, 150443030)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(\n",
    "    sentences=df[\"tokens\"],\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")\n",
    "word2vec_model.train(df[\"tokens\"], total_examples=len(df[\"tokens\"]), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(word2vec_model.wv.key_to_index.keys())\n",
    "sequences = prepare_training_sequences(df[\"text\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# too long to run otherwise\n",
    "sequences = sequences[:1000000]\n",
    "\n",
    "train_sequences, test_sequences = train_test_split(\n",
    "    sequences, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = PoemDataset(train_sequences, word2vec_model, vocabulary)\n",
    "test_dataset = PoemDataset(test_sequences, word2vec_model, vocabulary)\n",
    "\n",
    "batch_size = 1024\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "hidden_size = 256\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "model = PoemGeneratorMLP(embedding_dim, hidden_size, vocab_size, dropout=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PoemGeneratorMLP(embedding_dim, hidden_size, vocab_size, dropout=0.5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [Train]: 100%|██████████| 879/879 [03:45<00:00,  3.91it/s, loss=6.2231]\n",
      "Epoch 1/1 [Test]: 100%|██████████| 98/98 [00:11<00:00,  8.29it/s, loss=6.3625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:\n",
      "Average Training Loss: 6.1852\n",
      "Average Test Loss: 6.5589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([6.185246550046815], [6.558924494957437])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_poem_generator(\n",
    "    model, train_loader, test_loader, loss_fn, optimizer, num_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poem(\n",
    "    model, word2vec_model, vocabulary, max_length=50, temperature=0.7, start_word=None\n",
    "):\n",
    "    if start_word is None:\n",
    "        current_word = np.random.choice(vocabulary)\n",
    "    else:\n",
    "        current_word = start_word\n",
    "\n",
    "    generated_poem = [current_word]\n",
    "    word_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        if current_word in word2vec_model.wv:\n",
    "            word_vector = word2vec_model.wv[current_word]\n",
    "            input_vector = torch.tensor(word_vector, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(input_vector)\n",
    "\n",
    "            output = output / temperature\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "\n",
    "            next_word_idx = torch.multinomial(probs, 1).item()\n",
    "            next_word = vocabulary[next_word_idx]\n",
    "\n",
    "            generated_poem.append(next_word)\n",
    "            current_word = next_word\n",
    "\n",
    "            if np.random.random() < 0.1:\n",
    "                current_word = np.random.choice(vocabulary)\n",
    "\n",
    "    return \" \".join(generated_poem)\n",
    "\n",
    "\n",
    "def format_poem(text, line_length=40):\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = []\n",
    "    current_length = 0\n",
    "\n",
    "    for word in words:\n",
    "        if current_length + len(word) + 1 <= line_length:\n",
    "            current_line.append(word)\n",
    "            current_length += len(word) + 1\n",
    "        else:\n",
    "            lines.append(\" \".join(current_line))\n",
    "            current_line = [word]\n",
    "            current_length = len(word)\n",
    "\n",
    "    if current_line:\n",
    "        lines.append(\" \".join(current_line))\n",
    "\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_poems(\n",
    "    model, word2vec_model, vocabulary, num_poems=100, max_length=50\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    generated_poems = []\n",
    "    for _ in tqdm(range(num_poems), desc=\"Generating poems\"):\n",
    "        poem = generate_poem(model, word2vec_model, vocabulary, max_length=max_length)\n",
    "        generated_poems.append(poem)\n",
    "\n",
    "    return generated_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "far off the song was laid them here\n",
      "they are all the study and fly from\n",
      "which seem the simple youth which flame\n",
      "of the day we must be sure the happy our\n",
      "fathers and the tramp a broad and green\n",
      "the chase the sorcerer puppy in the sun\n",
      "and an at the storm like down through\n",
      "the world my passion and the whole child\n",
      "was it is a week was the moons with a\n",
      "woe and whiles when through with a year\n",
      "when we know i mean the leafless the\n",
      "ground from the winds rise and his you\n",
      "ll be\n"
     ]
    }
   ],
   "source": [
    "generated_text = generate_poem(\n",
    "    model,\n",
    "    word2vec_model,\n",
    "    vocabulary,\n",
    "    max_length=100,\n",
    "    temperature=0.7,\n",
    "    start_word=\"far\",\n",
    ")\n",
    "formatted_poem = format_poem(generated_text)\n",
    "print(formatted_poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_rouge(generated_poems, reference_poems):\n",
    "    \"\"\"\n",
    "    Evaluate generated poems against reference poems using ROUGE metrics.\n",
    "    \"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(\n",
    "        [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], use_stemmer=True\n",
    "    )\n",
    "\n",
    "    rouge_scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": [], \"rougeLsum\": []}\n",
    "\n",
    "    for gen_poem, ref_poem in tqdm(\n",
    "        zip(generated_poems, reference_poems),\n",
    "        total=len(generated_poems),\n",
    "        desc=\"Calculating ROUGE scores\",\n",
    "    ):\n",
    "        scores = scorer.score(ref_poem, gen_poem)\n",
    "\n",
    "        for metric in rouge_scores.keys():\n",
    "            rouge_scores[metric].append(scores[metric].fmeasure)\n",
    "\n",
    "    results = {}\n",
    "    for metric in rouge_scores:\n",
    "        results[metric] = np.mean(rouge_scores[metric])\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_with_bertscore(generated_poems, reference_poems):\n",
    "    \"\"\"\n",
    "    Evaluate generated poems against reference poems using BERTScore.\n",
    "    \"\"\"\n",
    "    generated_poems = [str(poem) for poem in generated_poems]\n",
    "    reference_poems = [str(poem) for poem in reference_poems]\n",
    "\n",
    "    try:\n",
    "        P, R, F1 = score(generated_poems, reference_poems, lang=\"en\", verbose=True)\n",
    "        return {\n",
    "            \"Precision\": P.mean().item(),\n",
    "            \"Recall\": R.mean().item(),\n",
    "            \"F1\": F1.mean().item(),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error in BERTScore evaluation: {e}\")\n",
    "        return {\"Precision\": 0.0, \"Recall\": 0.0, \"F1\": 0.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, word2vec_model, vocabulary, test_poems, num_samples=100):\n",
    "    \"\"\"\n",
    "    Evaluate the model by generating poems and comparing them with test poems.\n",
    "    \"\"\"\n",
    "    generated_poems = []\n",
    "    for _ in tqdm(range(num_samples), desc=\"Generating poems for evaluation\"):\n",
    "        start_word = np.random.choice(vocabulary)\n",
    "        generated_poem = generate_poem(\n",
    "            model,\n",
    "            word2vec_model,\n",
    "            vocabulary,\n",
    "            max_length=50,\n",
    "            temperature=0.7,\n",
    "            start_word=start_word,\n",
    "        )\n",
    "        generated_poems.append(str(generated_poem))\n",
    "\n",
    "    selected_test_poems = [\n",
    "        str(poem) for poem in np.random.choice(test_poems, num_samples, replace=False)\n",
    "    ]\n",
    "\n",
    "    rouge_scores = evaluate_with_rouge(generated_poems, selected_test_poems)\n",
    "    bert_scores = evaluate_with_bertscore(generated_poems, selected_test_poems)\n",
    "\n",
    "    print(\"ROUGE Scores:\")\n",
    "    for metric in [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]:\n",
    "        print(f\"{metric}: {rouge_scores[metric]:.4f}\")\n",
    "\n",
    "    print(\"\\nBERTScore:\")\n",
    "    print(f\"Precision: {bert_scores['Precision']:.4f}\")\n",
    "    print(f\"Recall: {bert_scores['Recall']:.4f}\")\n",
    "    print(f\"F1: {bert_scores['F1']:.4f}\")\n",
    "\n",
    "    return {**rouge_scores, **bert_scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating poems for evaluation: 100%|██████████| 100/100 [00:31<00:00,  3.16it/s]\n",
      "Calculating ROUGE scores: 100%|██████████| 100/100 [00:00<00:00, 109.52it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:26<00:00,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 28.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 26.57 seconds, 3.76 sentences/sec\n",
      "ROUGE Scores:\n",
      "rouge1: 0.1633\n",
      "rouge2: 0.0111\n",
      "rougeL: 0.1089\n",
      "rougeLsum: 0.1559\n",
      "\n",
      "BERTScore:\n",
      "Precision: 0.7905\n",
      "Recall: 0.7643\n",
      "F1: 0.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_poems = df[\"text\"].tolist()\n",
    "results = evaluate_model(model, word2vec_model, vocabulary, test_poems, num_samples=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
